//! UTF-8 Integration Test
//!
//! This test verifies that our UTF-8 decoder works correctly in real streaming scenarios
//! by directly testing the decoder with realistic data patterns.

use siumai::utils::Utf8StreamDecoder;

#[test]
fn test_utf8_decoder_with_sse_like_data() {
    let mut decoder = Utf8StreamDecoder::new();
    
    // Simulate SSE data with Chinese content that might be truncated
    let sse_data = r#"data: {"choices":[{"delta":{"content":"ä½ å¥½ï¼å…³äºUTF-8ç¼–ç çš„é—®é¢˜ï¼Œæˆ‘æ¥è¯¦ç»†è§£é‡Šä¸€ä¸‹ï¼š\n\nUTF-8æ˜¯ä¸€ç§å¯å˜é•¿åº¦çš„å­—ç¬¦ç¼–ç ï¼Œä¸­æ–‡å­—ç¬¦é€šå¸¸å ç”¨3ä¸ªå­—èŠ‚ã€‚ä¾‹å¦‚ï¼š'ä¸­'å­—çš„UTF-8ç¼–ç æ˜¯ 0xE4 0xB8 0xADã€‚\n\nåœ¨ç½‘ç»œä¼ è¾“ä¸­ï¼Œå¦‚æœæ•°æ®åŒ…åœ¨å­—ç¬¦è¾¹ç•Œè¢«æˆªæ–­ï¼Œå°±å¯èƒ½å‡ºç°ä¹±ç ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆéœ€è¦UTF-8æµå¼è§£ç å™¨çš„åŸå› ã€‚ğŸŒâœ¨"}}]}

"#;
    
    let bytes = sse_data.as_bytes();
    println!("Original SSE data length: {} bytes", bytes.len());
    
    // Test with various chunk sizes that might split UTF-8 characters
    for chunk_size in [1, 2, 3, 5, 7, 11, 13] {
        println!("\n=== Testing with chunk size: {} ===", chunk_size);
        let mut decoder = Utf8StreamDecoder::new();
        let mut result = String::new();
        
        for (i, chunk) in bytes.chunks(chunk_size).enumerate() {
            let decoded = decoder.decode(chunk);
            println!("Chunk {}: {} bytes -> {} chars", i, chunk.len(), decoded.len());
            result.push_str(&decoded);
        }
        
        // Flush any remaining bytes
        let remaining = decoder.flush();
        result.push_str(&remaining);
        
        // Verify the result matches the original
        assert_eq!(result, sse_data, "Chunk size {} failed", chunk_size);
        assert!(!result.contains('ï¿½'), "Chunk size {} produced corruption", chunk_size);
        
        // Verify Chinese characters are intact
        assert!(result.contains("ä½ å¥½"), "Chinese greeting missing with chunk size {}", chunk_size);
        assert!(result.contains("ä¸­æ–‡å­—ç¬¦"), "Chinese characters missing with chunk size {}", chunk_size);
        assert!(result.contains("ğŸŒ"), "Emoji missing with chunk size {}", chunk_size);
        assert!(result.contains("âœ¨"), "Sparkles emoji missing with chunk size {}", chunk_size);
    }
}

#[test]
fn test_utf8_decoder_with_thinking_content() {
    let mut decoder = Utf8StreamDecoder::new();
    
    // Simulate thinking content with mixed languages
    let thinking_data = r#"<think>
è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜ï¼Œéœ€è¦ä»”ç»†æ€è€ƒã€‚è®©æˆ‘åˆ†æä¸€ä¸‹ï¼š
1. ç”¨æˆ·è¯¢é—®äº†å…³äºUTF-8ç¼–ç çš„é—®é¢˜ ğŸ¤”
2. æˆ‘éœ€è¦æä¾›å‡†ç¡®çš„æŠ€æœ¯ä¿¡æ¯
3. åŒæ—¶è¦è€ƒè™‘ä¸­æ–‡å­—ç¬¦çš„å¤„ç†
è¿™æ¶‰åŠåˆ°å­—èŠ‚è¾¹ç•Œçš„é—®é¢˜...
</think>

å®é™…å›ç­”ï¼šUTF-8ç¼–ç ç¡®å®éœ€è¦ç‰¹æ®Šå¤„ç†ã€‚"#;
    
    let bytes = thinking_data.as_bytes();
    
    // Test with single-byte chunks (worst case)
    let mut result = String::new();
    for byte in bytes {
        let decoded = decoder.decode(&[*byte]);
        result.push_str(&decoded);
    }
    
    let remaining = decoder.flush();
    result.push_str(&remaining);
    
    // Verify integrity
    assert_eq!(result, thinking_data);
    assert!(!result.contains('ï¿½'), "Should not contain replacement characters");
    
    // Verify thinking tags are intact
    assert!(result.contains("<think>"), "Should contain opening thinking tag");
    assert!(result.contains("</think>"), "Should contain closing thinking tag");
    
    // Verify Chinese content
    assert!(result.contains("è¿™æ˜¯ä¸€ä¸ªå¤æ‚çš„é—®é¢˜"), "Should contain Chinese thinking content");
    assert!(result.contains("UTF-8ç¼–ç "), "Should contain UTF-8 reference");
    assert!(result.contains("ğŸ¤”"), "Should contain thinking emoji");
}

#[test]
fn test_utf8_decoder_with_json_boundaries() {
    let mut decoder = Utf8StreamDecoder::new();
    
    // Test JSON with Chinese content that might be split at various boundaries
    let json_data = r#"{"id":"test-123","object":"chat.completion.chunk","choices":[{"index":0,"delta":{"content":"æµ‹è¯•ä¸­æ–‡å†…å®¹ï¼šä½ å¥½ä¸–ç•Œï¼ğŸŒ è¿™æ˜¯ä¸€ä¸ªåŒ…å«emojiçš„æµ‹è¯•ã€‚"},"finish_reason":null}]}"#;
    
    let bytes = json_data.as_bytes();
    
    // Test splitting at every possible position
    for split_pos in 1..bytes.len() {
        let mut decoder = Utf8StreamDecoder::new();
        let mut result = String::new();
        
        // Split into two chunks at split_pos
        let chunk1 = &bytes[..split_pos];
        let chunk2 = &bytes[split_pos..];
        
        let decoded1 = decoder.decode(chunk1);
        let decoded2 = decoder.decode(chunk2);
        let remaining = decoder.flush();
        
        result.push_str(&decoded1);
        result.push_str(&decoded2);
        result.push_str(&remaining);
        
        // Verify integrity
        assert_eq!(result, json_data, "Split at position {} failed", split_pos);
        assert!(!result.contains('ï¿½'), "Split at position {} produced corruption", split_pos);
    }
}

#[test]
fn test_utf8_decoder_performance_with_large_content() {
    let mut decoder = Utf8StreamDecoder::new();
    
    // Create a large text with mixed content
    let mut large_text = String::new();
    for i in 0..1000 {
        large_text.push_str(&format!("ç¬¬{}è¡Œï¼šè¿™æ˜¯åŒ…å«ä¸­æ–‡ã€Englishå’ŒemojiğŸš€çš„æ··åˆå†…å®¹ã€‚\n", i));
    }
    
    let bytes = large_text.as_bytes();
    println!("Large text size: {} bytes", bytes.len());
    
    // Process with small chunks
    let chunk_size = 7; // Chosen to frequently split UTF-8 sequences
    let mut result = String::new();
    let mut chunk_count = 0;
    
    for chunk in bytes.chunks(chunk_size) {
        let decoded = decoder.decode(chunk);
        result.push_str(&decoded);
        chunk_count += 1;
    }
    
    let remaining = decoder.flush();
    result.push_str(&remaining);
    
    println!("Processed {} chunks", chunk_count);
    
    // Verify integrity
    assert_eq!(result, large_text);
    assert!(!result.contains('ï¿½'), "Large content processing should not produce corruption");
    
    // Verify some specific content
    assert!(result.contains("ç¬¬0è¡Œ"), "Should contain first line");
    assert!(result.contains("ç¬¬999è¡Œ"), "Should contain last line");
    assert!(result.contains("ğŸš€"), "Should contain rocket emoji");
}

#[test]
fn test_utf8_decoder_edge_cases() {
    // Test empty input
    let mut decoder = Utf8StreamDecoder::new();
    assert_eq!(decoder.decode(&[]), "");
    assert_eq!(decoder.flush(), "");
    
    // Test single ASCII character
    let mut decoder = Utf8StreamDecoder::new();
    assert_eq!(decoder.decode(b"A"), "A");
    assert_eq!(decoder.flush(), "");
    
    // Test incomplete UTF-8 sequence at end
    let mut decoder = Utf8StreamDecoder::new();
    let incomplete = vec![0xE4, 0xB8]; // First 2 bytes of "ä¸­"
    assert_eq!(decoder.decode(&incomplete), "");
    assert_eq!(decoder.flush(), ""); // Should discard invalid sequence
    
    // Test mixed valid and invalid sequences
    let mut decoder = Utf8StreamDecoder::new();
    let mixed = b"Hello\xE4\xB8\xADWorld"; // "Helloä¸­World"
    assert_eq!(decoder.decode(mixed), "Helloä¸­World");
    assert_eq!(decoder.flush(), "");
}

#[test]
fn test_utf8_decoder_reset_functionality() {
    let mut decoder = Utf8StreamDecoder::new();
    
    // Add some incomplete data
    let incomplete = vec![0xE4, 0xB8]; // First 2 bytes of "ä¸­"
    decoder.decode(&incomplete);
    assert!(decoder.has_buffered_bytes());
    assert_eq!(decoder.buffered_byte_count(), 2);
    
    // Reset should clear buffer
    decoder.reset();
    assert!(!decoder.has_buffered_bytes());
    assert_eq!(decoder.buffered_byte_count(), 0);
    
    // Should work normally after reset
    let complete = "ä½ å¥½ä¸–ç•Œ".as_bytes();
    let result = decoder.decode(complete);
    assert_eq!(result, "ä½ å¥½ä¸–ç•Œ");
}
