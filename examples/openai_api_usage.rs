//! OpenAI API ä½¿ç”¨ç¤ºä¾‹
//!
//! è¿™ä¸ªç¤ºä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ siumai åº“è°ƒç”¨ OpenAI çš„å„ç§ API ç«¯ç‚¹ï¼š
//! - æ–‡æœ¬åµŒå…¥ (Embeddings)
//! - æ–‡æœ¬è½¬è¯­éŸ³ (Text-to-Speech)
//! - è¯­éŸ³è½¬æ–‡æœ¬ (Speech-to-Text)
//! - å›¾åƒç”Ÿæˆ (Image Generation)

use siumai::{
    providers::openai::{OpenAiAudio, OpenAiConfig, OpenAiEmbeddings, OpenAiImages},
    traits::{AudioCapability, EmbeddingCapability, ImageGenerationCapability},
    types::{ImageGenerationRequest, TtsRequest},
};
use std::env;

#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    // åˆå§‹åŒ–æ—¥å¿—
    env_logger::init();

    println!("ğŸš€ Siumai OpenAI API ä½¿ç”¨ç¤ºä¾‹");
    println!("==============================");

    // è·å– API å¯†é’¥
    let api_key = env::var("OPENAI_API_KEY").unwrap_or_else(|_| {
        println!("âš ï¸  è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");
        std::process::exit(1);
    });

    // åˆ›å»º OpenAI é…ç½®
    let config = OpenAiConfig::new(api_key);
    let http_client = reqwest::Client::new();

    // 1. æ–‡æœ¬åµŒå…¥ç¤ºä¾‹
    println!("\nğŸ“Š 1. æ–‡æœ¬åµŒå…¥ç¤ºä¾‹");
    println!("------------------");

    let embeddings_client = OpenAiEmbeddings::new(config.clone(), http_client.clone());

    let texts = vec![
        "Hello, world!".to_string(),
        "ä½ å¥½ï¼Œä¸–ç•Œï¼".to_string(),
        "Rust is a great programming language.".to_string(),
    ];

    match embeddings_client.embed(texts.clone()).await {
        Ok(response) => {
            println!("âœ… æˆåŠŸç”Ÿæˆ {} ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡", response.embeddings.len());
            println!("ğŸ“ åµŒå…¥ç»´åº¦: {}", response.embeddings[0].len());
            println!("ğŸ¤– ä½¿ç”¨æ¨¡å‹: {}", response.model);
            if let Some(usage) = response.usage {
                println!("ğŸ“ˆ Token ä½¿ç”¨: {} ä¸ª", usage.total_tokens);
            }
        }
        Err(e) => println!("âŒ åµŒå…¥ç”Ÿæˆå¤±è´¥: {}", e),
    }

    // 2. æ–‡æœ¬è½¬è¯­éŸ³ç¤ºä¾‹
    println!("\nğŸµ 2. æ–‡æœ¬è½¬è¯­éŸ³ç¤ºä¾‹");
    println!("--------------------");

    let audio_client = OpenAiAudio::new(config.clone(), http_client.clone());

    let tts_request = TtsRequest {
        text: "Hello, this is a test of the text-to-speech functionality in Siumai.".to_string(),
        voice: Some("alloy".to_string()),
        format: Some("mp3".to_string()),
        speed: Some(1.0),
        model: Some("tts-1".to_string()),
        extra_params: std::collections::HashMap::new(),
    };

    match audio_client.text_to_speech(tts_request).await {
        Ok(response) => {
            println!("âœ… æˆåŠŸç”Ÿæˆè¯­éŸ³");
            println!("ğŸ“„ éŸ³é¢‘æ ¼å¼: {}", response.format);
            println!("ğŸ“ éŸ³é¢‘å¤§å°: {} å­—èŠ‚", response.audio_data.len());

            // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            if let Err(e) = std::fs::write("output.mp3", &response.audio_data) {
                println!("âš ï¸  ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: {}", e);
            } else {
                println!("ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜ä¸º output.mp3");
            }
        }
        Err(e) => println!("âŒ è¯­éŸ³ç”Ÿæˆå¤±è´¥: {}", e),
    }

    // 3. å›¾åƒç”Ÿæˆç¤ºä¾‹
    println!("\nğŸ¨ 3. å›¾åƒç”Ÿæˆç¤ºä¾‹");
    println!("------------------");

    let images_client = OpenAiImages::new(config.clone(), http_client.clone());

    let image_request = ImageGenerationRequest {
        prompt: "A beautiful sunset over mountains, digital art style".to_string(),
        negative_prompt: None,
        size: Some("1024x1024".to_string()),
        count: 1,
        model: Some("dall-e-3".to_string()),
        quality: Some("standard".to_string()),
        style: Some("vivid".to_string()),
        seed: None,
        steps: None,
        guidance_scale: None,
        enhance_prompt: None,
        response_format: Some("url".to_string()),
        extra_params: std::collections::HashMap::new(),
    };

    match images_client.generate_images(image_request).await {
        Ok(response) => {
            println!("âœ… æˆåŠŸç”Ÿæˆ {} å¼ å›¾åƒ", response.images.len());
            for (i, image) in response.images.iter().enumerate() {
                if let Some(url) = &image.url {
                    println!("ğŸ–¼ï¸  å›¾åƒ {}: {}", i + 1, url);
                }
                if let Some(revised_prompt) = &image.revised_prompt {
                    println!("ğŸ“ ä¿®è®¢åçš„æç¤º: {}", revised_prompt);
                }
            }
        }
        Err(e) => println!("âŒ å›¾åƒç”Ÿæˆå¤±è´¥: {}", e),
    }

    // 4. æ˜¾ç¤ºæ”¯æŒçš„åŠŸèƒ½
    println!("\nğŸ“‹ 4. æ”¯æŒçš„åŠŸèƒ½");
    println!("----------------");

    println!(
        "ğŸ” åµŒå…¥æ¨¡å‹: {:?}",
        embeddings_client.supported_embedding_models()
    );
    println!("ğŸµ éŸ³é¢‘åŠŸèƒ½: {:?}", audio_client.supported_features());
    println!("ğŸ¨ å›¾åƒå°ºå¯¸: {:?}", images_client.get_supported_sizes());
    println!("ğŸ“„ å›¾åƒæ ¼å¼: {:?}", images_client.get_supported_formats());

    println!("\nâœ¨ ç¤ºä¾‹å®Œæˆï¼");
    println!("ğŸ’¡ æç¤ºï¼šç¡®ä¿è®¾ç½®äº†æœ‰æ•ˆçš„ OPENAI_API_KEY ç¯å¢ƒå˜é‡");

    Ok(())
}
