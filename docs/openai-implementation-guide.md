# OpenAI API å®ç°æŒ‡å—

## æ¦‚è¿°

æœ¬æ–‡æ¡£æä¾›äº†åŸºäº OpenAI OpenAPI è§„èŒƒ (`docs/openapi.documented.yml`) çš„è¯¦ç»†å®ç°æŒ‡å—ï¼ŒåŒ…å«å…·ä½“çš„ä»£ç ç¤ºä¾‹ã€OpenAPI å¼•ç”¨å’Œå®ç°æ­¥éª¤ã€‚

## ğŸ¯ é˜¶æ®µ 1: Chat Completions API ä¿®å¤

### 1.1 æ¶ˆæ¯è§’è‰²æ‰©å±•

**OpenAPI è§„èŒƒå¼•ç”¨:**
- æ–‡ä»¶: `docs/openapi.documented.yml`
- è¡Œå·: 3181-3189 (Chat Completions ç¤ºä¾‹)
- å†…å®¹: æ˜¾ç¤º `"role": "developer"` çš„ä½¿ç”¨

**å½“å‰é—®é¢˜:**
```rust
// src/types.rs - ç¼ºå°‘ developer è§’è‰²
pub enum ChatRole {
    System,
    User,
    Assistant,
    Tool,
}
```

**ä¿®å¤å®ç°:**
```rust
// src/types.rs
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
#[serde(rename_all = "lowercase")]
pub enum ChatRole {
    System,
    User,
    Assistant,
    Developer,  // æ–°å¢ - ç”¨äºå¼€å‘è€…çº§åˆ«çš„ç³»ç»ŸæŒ‡ä»¤
    Tool,
}
```

### 1.2 æ–°è¯·æ±‚å‚æ•°å®ç°

**OpenAPI è§„èŒƒå¼•ç”¨:**
- æ–‡ä»¶: `docs/openapi.documented.yml`
- è¡Œå·: 30441-30500 (CreateChatCompletionRequest schema)

**éœ€è¦æ·»åŠ çš„å‚æ•°:**

1. **modalities å‚æ•°**
   ```yaml
   # OpenAPI å®šä¹‰ (è¡Œ 30463-30464)
   modalities:
     $ref: '#/components/schemas/ResponseModalities'
   ```

2. **reasoning_effort å‚æ•°**
   ```yaml
   # OpenAPI å®šä¹‰ (è¡Œ 30465-30466)
   reasoning_effort:
     $ref: '#/components/schemas/ReasoningEffort'
   ```

3. **max_completion_tokens å‚æ•°**
   ```yaml
   # OpenAPI å®šä¹‰ (è¡Œ 30467-30472)
   max_completion_tokens:
     description: >
       An upper bound for the number of tokens that can be generated for a completion,
       including visible output tokens and reasoning tokens.
     type: integer
     nullable: true
   ```

**å®ç°ä»£ç :**
```rust
// src/providers/openai/types.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum ReasoningEffort {
    Low,
    Medium,
    High,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ResponseModalities {
    pub text: Option<bool>,
    pub audio: Option<bool>,
}

// src/providers/openai/chat.rs - æ‰©å±•è¯·æ±‚ç»“æ„
#[derive(Debug, Clone, Serialize)]
pub struct OpenAiChatRequest {
    pub model: String,
    pub messages: Vec<ChatMessage>,
    
    // æ–°å¢å‚æ•°
    #[serde(skip_serializing_if = "Option::is_none")]
    pub modalities: Option<Vec<String>>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub reasoning_effort: Option<ReasoningEffort>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_completion_tokens: Option<u32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub frequency_penalty: Option<f32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub presence_penalty: Option<f32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub logit_bias: Option<HashMap<String, f32>>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub seed: Option<u32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub user: Option<String>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub service_tier: Option<String>,
    
    // ç°æœ‰å‚æ•°
    #[serde(skip_serializing_if = "Option::is_none")]
    pub temperature: Option<f32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub top_p: Option<f32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub max_tokens: Option<u32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub stream: Option<bool>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tools: Option<Vec<Tool>>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub tool_choice: Option<ToolChoice>,
}
```

### 1.3 å‚æ•°éªŒè¯é€»è¾‘

```rust
impl OpenAiChatRequest {
    pub fn validate(&self) -> Result<(), LlmError> {
        // éªŒè¯ frequency_penalty èŒƒå›´
        if let Some(penalty) = self.frequency_penalty {
            if penalty < -2.0 || penalty > 2.0 {
                return Err(LlmError::InvalidInput(
                    "frequency_penalty must be between -2.0 and 2.0".to_string()
                ));
            }
        }
        
        // éªŒè¯ presence_penalty èŒƒå›´
        if let Some(penalty) = self.presence_penalty {
            if penalty < -2.0 || penalty > 2.0 {
                return Err(LlmError::InvalidInput(
                    "presence_penalty must be between -2.0 and 2.0".to_string()
                ));
            }
        }
        
        // éªŒè¯æ¨ç†æ¨¡å‹çš„å‚æ•°å…¼å®¹æ€§
        if self.reasoning_effort.is_some() {
            // æ¨ç†æ¨¡å‹é€šå¸¸ä¸æ”¯æŒæŸäº›å‚æ•°
            if self.temperature.is_some() || self.top_p.is_some() {
                return Err(LlmError::InvalidInput(
                    "reasoning models do not support temperature or top_p parameters".to_string()
                ));
            }
        }
        
        Ok(())
    }
}
```

## ğŸµ é˜¶æ®µ 2: Audio API å¢å¼º

### 2.1 TTS æ–°æ¨¡å‹å’Œå‚æ•°

**OpenAPI è§„èŒƒå¼•ç”¨:**
- æ–‡ä»¶: `docs/openapi.documented.yml`
- è¡Œå·: 33346-33380 (CreateSpeechRequest schema)

**æ–°æ¨¡å‹æ”¯æŒ:**
```yaml
# OpenAPI å®šä¹‰ (è¡Œ 33356-33359)
model:
  enum:
    - tts-1
    - tts-1-hd
    - gpt-4o-mini-tts  # æ–°æ¨¡å‹
```

**instructions å‚æ•°:**
```yaml
# OpenAPI å®šä¹‰ (è¡Œ 33365-33370)
instructions:
  type: string
  description: >-
    Control the voice of your generated audio with additional instructions.
    Does not work with `tts-1` or `tts-1-hd`.
  maxLength: 4096
```

**å®ç°ä»£ç :**
```rust
// src/providers/openai/audio.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "kebab-case")]
pub enum TtsModel {
    Tts1,
    Tts1Hd,
    #[serde(rename = "gpt-4o-mini-tts")]
    Gpt4oMiniTts,  // æ–°å¢
}

#[derive(Debug, Clone, Serialize)]
pub struct OpenAiTtsRequest {
    pub model: String,
    pub input: String,
    pub voice: String,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub response_format: Option<String>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub speed: Option<f32>,
    
    #[serde(skip_serializing_if = "Option::is_none")]
    pub instructions: Option<String>,  // æ–°å¢
}

impl OpenAiTtsRequest {
    pub fn validate(&self) -> Result<(), LlmError> {
        // éªŒè¯ instructions å‚æ•°çš„æ¨¡å‹å…¼å®¹æ€§
        if self.instructions.is_some() {
            if self.model == "tts-1" || self.model == "tts-1-hd" {
                return Err(LlmError::InvalidInput(
                    "instructions parameter is not supported for tts-1 and tts-1-hd models".to_string()
                ));
            }
        }
        
        // éªŒè¯è¾“å…¥é•¿åº¦
        if self.input.len() > 4096 {
            return Err(LlmError::InvalidInput(
                "input text cannot exceed 4096 characters".to_string()
            ));
        }
        
        // éªŒè¯ instructions é•¿åº¦
        if let Some(instructions) = &self.instructions {
            if instructions.len() > 4096 {
                return Err(LlmError::InvalidInput(
                    "instructions cannot exceed 4096 characters".to_string()
                ));
            }
        }
        
        Ok(())
    }
}
```

### 2.2 æ–°è¯­éŸ³é€‰é¡¹

**OpenAPI è§„èŒƒå¼•ç”¨:**
- æ–‡ä»¶: `docs/openapi.documented.yml`
- è¡Œå·: 33371-33376 (voice å‚æ•°å®šä¹‰)

```yaml
voice:
  description: >-
    The voice to use when generating the audio. Supported voices are `alloy`, `ash`, `ballad`,
    `coral`, `echo`, `fable`, `onyx`, `nova`, `sage`, `shimmer`, and `verse`.
```

**å®ç°ä»£ç :**
```rust
// src/providers/openai/audio.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
pub enum TtsVoice {
    Alloy,
    Ash,      // æ–°å¢
    Ballad,   // æ–°å¢
    Coral,    // æ–°å¢
    Echo,
    Fable,
    Nova,
    Onyx,
    Sage,     // æ–°å¢
    Shimmer,
    Verse,    // æ–°å¢
}

impl TtsVoice {
    pub fn all_voices() -> Vec<TtsVoice> {
        vec![
            TtsVoice::Alloy,
            TtsVoice::Ash,
            TtsVoice::Ballad,
            TtsVoice::Coral,
            TtsVoice::Echo,
            TtsVoice::Fable,
            TtsVoice::Nova,
            TtsVoice::Onyx,
            TtsVoice::Sage,
            TtsVoice::Shimmer,
            TtsVoice::Verse,
        ]
    }
    
    pub fn is_supported_by_model(&self, model: &TtsModel) -> bool {
        // æ‰€æœ‰è¯­éŸ³éƒ½æ”¯æŒæ‰€æœ‰æ¨¡å‹
        true
    }
}
```

### 2.3 æµå¼è½¬å½•æ”¯æŒ

**OpenAPI è§„èŒƒå¼•ç”¨:**
- æ–‡ä»¶: `docs/openapi.documented.yml`
- è¡Œå·: 1210-1245 (Streaming transcription ç¤ºä¾‹)

**å®ç°ä»£ç :**
```rust
// src/providers/openai/audio.rs
#[derive(Debug, Clone)]
pub struct TranscriptionRequest {
    pub file: Vec<u8>,
    pub model: String,
    pub language: Option<String>,
    pub prompt: Option<String>,
    pub response_format: Option<String>,
    pub temperature: Option<f32>,
    pub timestamp_granularities: Option<Vec<String>>,
    pub stream: Option<bool>,  // æ–°å¢æµå¼æ”¯æŒ
}

impl OpenAiAudio {
    pub async fn transcribe_stream(
        &self,
        request: TranscriptionRequest,
    ) -> Result<impl Stream<Item = Result<TranscriptionEvent, LlmError>>, LlmError> {
        if !request.stream.unwrap_or(false) {
            return Err(LlmError::InvalidInput(
                "stream parameter must be true for streaming transcription".to_string()
            ));
        }
        
        // æ„å»º multipart form data
        let form = self.build_transcription_form(request)?;
        let url = format!("{}/audio/transcriptions", self.config.base_url);
        
        // å‘é€æµå¼è¯·æ±‚
        let response = self.http_client
            .post(&url)
            .headers(self.build_headers()?)
            .multipart(form)
            .send()
            .await?;
            
        // è§£æ SSE æµ
        Ok(self.parse_transcription_stream(response))
    }
}
```

## ğŸ–¼ï¸ é˜¶æ®µ 3: Images API å®Œå–„

### 3.1 æ–°æ¨¡å‹æ”¯æŒ

**OpenAPI è§„èŒƒå¼•ç”¨:**
- æ–‡ä»¶: `docs/openapi.documented.yml`
- è¡Œå·: 32428-32442 (CreateImageRequest model å®šä¹‰)

```yaml
model:
  enum:
    - dall-e-2
    - dall-e-3
    - gpt-image-1  # æ–°æ¨¡å‹
  default: dall-e-2
```

**æç¤ºé•¿åº¦é™åˆ¶:**
- `gpt-image-1`: 32000 å­—ç¬¦ (è¡Œ 32424-32426)
- `dall-e-3`: 4000 å­—ç¬¦
- `dall-e-2`: 1000 å­—ç¬¦

**å®ç°ä»£ç :**
```rust
// src/providers/openai/images.rs
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum ImageModel {
    #[serde(rename = "dall-e-2")]
    DallE2,
    #[serde(rename = "dall-e-3")]
    DallE3,
    #[serde(rename = "gpt-image-1")]
    GptImage1,  // æ–°å¢
}

impl ImageModel {
    pub fn max_prompt_length(&self) -> usize {
        match self {
            ImageModel::DallE2 => 1000,
            ImageModel::DallE3 => 4000,
            ImageModel::GptImage1 => 32000,
        }
    }
    
    pub fn supports_editing(&self) -> bool {
        match self {
            ImageModel::DallE2 | ImageModel::GptImage1 => true,
            ImageModel::DallE3 => false,
        }
    }
    
    pub fn supports_variations(&self) -> bool {
        match self {
            ImageModel::DallE2 => true,
            ImageModel::DallE3 | ImageModel::GptImage1 => false,
        }
    }
}
```

### 3.2 å›¾åƒç¼–è¾‘åŠŸèƒ½

**OpenAPI è§„èŒƒå¼•ç”¨:**
- æ–‡ä»¶: `docs/openapi.documented.yml`
- è¡Œå·: 12695-12710 (/images/edits ç«¯ç‚¹)

```yaml
/images/edits:
  post:
    operationId: createImageEdit
    summary: >-
      Creates an edited or extended image given one or more source images and a prompt.
      This endpoint only supports `gpt-image-1` and `dall-e-2`.
```

**å®ç°ä»£ç :**
```rust
// src/providers/openai/images.rs
#[derive(Debug, Clone)]
pub struct ImageEditRequest {
    pub image: Vec<u8>,           // åŸå§‹å›¾åƒæ•°æ®
    pub mask: Option<Vec<u8>>,    // å¯é€‰çš„é®ç½©å›¾åƒ
    pub prompt: String,           // ç¼–è¾‘æè¿°
    pub model: Option<ImageModel>, // æ¨¡å‹é€‰æ‹©
    pub n: Option<u32>,          // ç”Ÿæˆæ•°é‡ (1-10)
    pub size: Option<String>,     // å›¾åƒå°ºå¯¸
    pub response_format: Option<String>, // url æˆ– b64_json
    pub user: Option<String>,     // ç”¨æˆ·æ ‡è¯†
}

impl ImageEditRequest {
    pub fn validate(&self) -> Result<(), LlmError> {
        // éªŒè¯æ¨¡å‹æ”¯æŒ
        if let Some(model) = &self.model {
            if !model.supports_editing() {
                return Err(LlmError::InvalidInput(
                    format!("Model {:?} does not support image editing", model)
                ));
            }
        }
        
        // éªŒè¯ç”Ÿæˆæ•°é‡
        if let Some(n) = self.n {
            if n < 1 || n > 10 {
                return Err(LlmError::InvalidInput(
                    "n must be between 1 and 10".to_string()
                ));
            }
        }
        
        Ok(())
    }
}

impl OpenAiImages {
    pub async fn edit_image(
        &self,
        request: ImageEditRequest,
    ) -> Result<ImageGenerationResponse, LlmError> {
        request.validate()?;
        
        // æ„å»º multipart form data
        let mut form = reqwest::multipart::Form::new();
        
        // æ·»åŠ å›¾åƒæ–‡ä»¶
        let image_part = reqwest::multipart::Part::bytes(request.image)
            .file_name("image.png")
            .mime_str("image/png")?;
        form = form.part("image", image_part);
        
        // æ·»åŠ é®ç½©æ–‡ä»¶ (å¦‚æœæä¾›)
        if let Some(mask) = request.mask {
            let mask_part = reqwest::multipart::Part::bytes(mask)
                .file_name("mask.png")
                .mime_str("image/png")?;
            form = form.part("mask", mask_part);
        }
        
        // æ·»åŠ å…¶ä»–å‚æ•°
        form = form.text("prompt", request.prompt);
        
        if let Some(model) = request.model {
            form = form.text("model", format!("{:?}", model).to_lowercase());
        }
        
        if let Some(n) = request.n {
            form = form.text("n", n.to_string());
        }
        
        // å‘é€è¯·æ±‚
        let url = format!("{}/images/edits", self.config.base_url);
        let response = self.http_client
            .post(&url)
            .headers(self.build_headers()?)
            .multipart(form)
            .send()
            .await?;
            
        self.parse_image_response(response).await
    }
}
```

---

*æœ¬å®ç°æŒ‡å—æä¾›äº†è¯¦ç»†çš„ä»£ç ç¤ºä¾‹å’Œ OpenAPI è§„èŒƒå¼•ç”¨ã€‚æ¯ä¸ªå®ç°éƒ½åŒ…å«äº†é€‚å½“çš„éªŒè¯é€»è¾‘å’Œé”™è¯¯å¤„ç†ã€‚*
